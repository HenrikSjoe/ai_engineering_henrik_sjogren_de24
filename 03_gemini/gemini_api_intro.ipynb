{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ca9f2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make decisions.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents = \"Explain how AI works in a few words\",\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15949129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some data engineering jokes, structured in short points:\n",
      "\n",
      "*   Why did the data pipeline break? The source team changed the schema... *again*.\n",
      "\n",
      "*   What's 'real-time' data to a data engineer? Batch processing... just with smaller batches and faster alerts when it inevitably breaks.\n",
      "\n",
      "*   A data scientist asks for clean data. A data engineer laughs, then cries, then runs an `ALTER TABLE`.\n",
      "\n",
      "*   We decided to build a data lake. Now we just have a data swamp with better marketing.\n",
      "\n",
      "*   My Airflow DAG just failed for the 10th time today. I guess it's time to add another `sleep(60)` to the retry logic.\n",
      "\n",
      "*   Manager: \"Can we just move this data from A to B?\" Data Engineer: \"Sure, just let me spin up a cluster, define 50 transformations, monitor 3 upstream dependencies, and allocate 2 weeks.\"\n",
      "\n",
      "*   Documentation? We just read the code... and then we cry.\n",
      "\n",
      "*   What's a data engineer's favorite type of coffee? Any kind, as long as it's brewed before the 3 AM pager goes off.\n",
      "\n",
      "*   Schema drift isn't a bug, it's a feature... of our unending torment.\n",
      "\n",
      "*   Why did the data engineer break up with Kafka? Too many uncommitted offsets.\n"
     ]
    }
   ],
   "source": [
    "def ask_gemini(prompt, model = \"gemini-2.5-flash\"):\n",
    "    response = client.models.generate_content(\n",
    "    model = model,\n",
    "    contents = prompt,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "response = ask_gemini(\"Give me some data engineering jokes, structured in short points\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "940dde66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text=\"\"\"Here are some data engineering jokes, structured in short points:\n",
       "\n",
       "*   Why did the data pipeline break? The source team changed the schema... *again*.\n",
       "\n",
       "*   What's 'real-time' data to a data engineer? Batch processing... just with smaller batches and faster alerts when it inevitably breaks.\n",
       "\n",
       "*   A data scientist asks for clean data. A data engineer laughs, then cries, then runs an `ALTER TABLE`.\n",
       "\n",
       "*   We decided to build a data lake. Now we just have a data swamp with better marketing.\n",
       "\n",
       "*   My Airflow DAG just failed for the 10th time today. I guess it's time to add another `sleep(60)` to the retry logic.\n",
       "\n",
       "*   Manager: \"Can we just move this data from A to B?\" Data Engineer: \"Sure, just let me spin up a cluster, define 50 transformations, monitor 3 upstream dependencies, and allocate 2 weeks.\"\n",
       "\n",
       "*   Documentation? We just read the code... and then we cry.\n",
       "\n",
       "*   What's a data engineer's favorite type of coffee? Any kind, as long as it's brewed before the 3 AM pager goes off.\n",
       "\n",
       "*   Schema drift isn't a bug, it's a feature... of our unending torment.\n",
       "\n",
       "*   Why did the data engineer break up with Kafka? Too many uncommitted offsets.\"\"\"\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "      index=0\n",
       "    ),\n",
       "  ],\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='Tk0caerpM6yI7M8P87vckAM',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=11>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=291,\n",
       "    prompt_token_count=12,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=12\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=1511,\n",
       "    total_token_count=1814\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69c161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "#Knows that GenerateContentResponse is a pydantic model\n",
    "# -> we can work in a OOP manner\n",
    "isinstance(response, BaseModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a25c3364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sdk_http_response', 'candidates', 'create_time', 'model_version', 'prompt_feedback', 'response_id', 'usage_metadata', 'automatic_function_calling_history', 'parsed'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c85a31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gemini-2.5-flash'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "971d221d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HttpResponse(\n",
       "  headers=<dict len=11>\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.sdk_http_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fab6a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Candidate(\n",
       "   content=Content(\n",
       "     parts=[\n",
       "       Part(\n",
       "         text=\"\"\"Here are some data engineering jokes, structured in short points:\n",
       " \n",
       " *   Why did the data pipeline break? The source team changed the schema... *again*.\n",
       " \n",
       " *   What's 'real-time' data to a data engineer? Batch processing... just with smaller batches and faster alerts when it inevitably breaks.\n",
       " \n",
       " *   A data scientist asks for clean data. A data engineer laughs, then cries, then runs an `ALTER TABLE`.\n",
       " \n",
       " *   We decided to build a data lake. Now we just have a data swamp with better marketing.\n",
       " \n",
       " *   My Airflow DAG just failed for the 10th time today. I guess it's time to add another `sleep(60)` to the retry logic.\n",
       " \n",
       " *   Manager: \"Can we just move this data from A to B?\" Data Engineer: \"Sure, just let me spin up a cluster, define 50 transformations, monitor 3 upstream dependencies, and allocate 2 weeks.\"\n",
       " \n",
       " *   Documentation? We just read the code... and then we cry.\n",
       " \n",
       " *   What's a data engineer's favorite type of coffee? Any kind, as long as it's brewed before the 3 AM pager goes off.\n",
       " \n",
       " *   Schema drift isn't a bug, it's a feature... of our unending torment.\n",
       " \n",
       " *   Why did the data engineer break up with Kafka? Too many uncommitted offsets.\"\"\"\n",
       "       ),\n",
       "     ],\n",
       "     role='model'\n",
       "   ),\n",
       "   finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "   index=0\n",
       " )]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a03174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are some data engineering jokes, structured in short points:\\n\\n*   Why did the data pipeline break? The source team changed the schema... *again*.\\n\\n*   What\\'s \\'real-time\\' data to a data engineer? Batch processing... just with smaller batches and faster alerts when it inevitably breaks.\\n\\n*   A data scientist asks for clean data. A data engineer laughs, then cries, then runs an `ALTER TABLE`.\\n\\n*   We decided to build a data lake. Now we just have a data swamp with better marketing.\\n\\n*   My Airflow DAG just failed for the 10th time today. I guess it\\'s time to add another `sleep(60)` to the retry logic.\\n\\n*   Manager: \"Can we just move this data from A to B?\" Data Engineer: \"Sure, just let me spin up a cluster, define 50 transformations, monitor 3 upstream dependencies, and allocate 2 weeks.\"\\n\\n*   Documentation? We just read the code... and then we cry.\\n\\n*   What\\'s a data engineer\\'s favorite type of coffee? Any kind, as long as it\\'s brewed before the 3 AM pager goes off.\\n\\n*   Schema drift isn\\'t a bug, it\\'s a feature... of our unending torment.\\n\\n*   Why did the data engineer break up with Kafka? Too many uncommitted offsets.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73901870",
   "metadata": {},
   "source": [
    "# Tokens\n",
    "\n",
    "- basic unit of text for LLM's\n",
    "- can be as short as one character or as long as one word\n",
    "- tokens uesd for billing\n",
    "\n",
    "Gemini free tier\n",
    "- Requests per minute (RPM): 10\n",
    "- Tokens per minut (TPM): 250 000\n",
    "- Request per day (RPD): 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b883b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=291,\n",
       "  prompt_token_count=12,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=12\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=1511,\n",
       "  total_token_count=1814\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Thinking is expensive\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678a9a7",
   "metadata": {},
   "source": [
    "# Thinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aee909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some data engineering jokes, structured in short points:\n",
      "\n",
      "*   **Q:** Why did the SQL query break up with the Data Scientist?\n",
      "    *   **A:** Because it felt too much **JOIN** pressure.\n",
      "\n",
      "*   **Q:** What's a data engineer's favorite type of music?\n",
      "    *   **A:** Anything with good **pipelines**!\n",
      "\n",
      "*   **Q:** How do you know a data engineer is at your party?\n",
      "    *   **A:** They're outside, asking if the **data flow** of people is optimized.\n",
      "\n",
      "*   **Q:** Why did the Data Lake get invited to all the parties?\n",
      "    *   **A:** Because it always brought all the **raw data**!\n",
      "\n",
      "*   **Q:** What's a data engineer's go-to pickup line?\n",
      "    *   **A:** \"Are you a **data warehouse**? Because I'd love to organize all your dimensions.\"\n",
      "\n",
      "*   **Q:** What do you call a lazy data engineer?\n",
      "    *   **A:** A **data swamp** creator.\n",
      "\n",
      "*   **Q:** Why are data engineers good at therapy?\n",
      "    *   **A:** They're excellent at finding the **root cause** of schema issues.\n",
      "\n",
      "*   **Q:** My boss asked me to explain our new ETL process.\n",
      "    *   **A:** I just said, \"It's all about moving bits, then making sure they **fit**.\"\n",
      "\n",
      "*   **Q:** What did the Data Catalog say to the confused Data Scientist?\n",
      "    *   **A:** \"Don't worry, I'll help you find your **metadata**.\"\n",
      "\n",
      "*   **Q:** Why did the streaming data get overwhelmed?\n",
      "    *   **A:** It couldn't handle the **throughput** of emotions.\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "prompt = \"Give me some data engineering jokes, structured in short points\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.5-flash\",\n",
    "    contents = prompt,\n",
    "    config= types.GenerateContentConfig(\n",
    "        thinking_config=types.ThinkingConfig(thinking_budget=0)\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6180c19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=390,\n",
       "  prompt_token_count=12,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=12\n",
       "    ),\n",
       "  ],\n",
       "  total_token_count=402\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd75ab8",
   "metadata": {},
   "source": [
    "# System instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fef638c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a breakdown of Object-Oriented Programming (OOP) and dunder methods in Python, with a focus on clarity and best practices:\n",
      "\n",
      "**Object-Oriented Programming (OOP)**\n",
      "\n",
      "OOP is a programming paradigm based on the concept of \"objects,\" which contain data (attributes) and code (methods) that operate on that data.  It promotes code reusability, modularity, and maintainability.\n",
      "\n",
      "*   **Key Concepts:**\n",
      "\n",
      "    *   **Classes:** Blueprints for creating objects.  They define the attributes and methods that objects of that class will possess.\n",
      "    *   **Objects:** Instances of a class. Each object has its own unique set of attribute values.\n",
      "    *   **Attributes:** Variables that store data associated with an object.  Think of them as the object's properties.\n",
      "    *   **Methods:** Functions defined within a class that operate on the object's data (attributes). They define the object's behavior.\n",
      "    *   **Encapsulation:** Bundling data (attributes) and methods that operate on that data within a class.  This hides the internal implementation details of an object and protects data from unauthorized access.\n",
      "    *   **Inheritance:**  The ability of a class (subclass/child class) to inherit attributes and methods from another class (superclass/parent class).  This promotes code reuse and the creation of specialized classes based on more general ones.\n",
      "    *   **Polymorphism:** The ability of objects of different classes to respond to the same method call in their own way.  This allows for more flexible and generic code.\n",
      "\n",
      "**Dunder Methods (Magic Methods)**\n",
      "\n",
      "*   **What They Are:** Special methods in Python that have double underscores (double underscores) at the beginning and end of their names (e.g., `__init__`, `__str__`, `__add__`).  They are also known as *magic methods*.\n",
      "\n",
      "*   **Purpose:** They define how objects of a class should behave in certain situations, such as:\n",
      "\n",
      "    *   Object creation (`__init__`)\n",
      "    *   String representation (`__str__`, `__repr__`)\n",
      "    *   Arithmetic operations (`__add__`, `__sub__`, `__mul__`, etc.)\n",
      "    *   Comparison operations (`__eq__`, `__ne__`, `__lt__`, etc.)\n",
      "    *   Attribute access (`__getattr__`, `__setattr__`, `__delattr__`)\n",
      "    *   Context management (`__enter__`, `__exit__`)\n",
      "    *   and many more\n",
      "\n",
      "*   **How They Work:**  Python automatically calls these methods when the corresponding operation is performed on an object.  For example, when you use the `+` operator on two objects, Python calls the `__add__` method of the first object (if it exists) to handle the addition.\n",
      "\n",
      "*   **Why Use Them:**\n",
      "\n",
      "    *   **Operator Overloading:** Allows you to define how standard operators (like `+`, `-`, `==`, etc.) should work with your custom objects.\n",
      "    *   **Customization:** Enables you to customize the behavior of your objects in various contexts.\n",
      "    *   **Pythonic Code:** Using dunder methods makes your code more consistent with Python's built-in types and conventions.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "```python\n",
      "class Vector:\n",
      "    def __init__(self, x, y):\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "\n",
      "    def __str__(self):\n",
      "        return f\"Vector({self.x}, {self.y})\"\n",
      "\n",
      "    def __add__(self, other):\n",
      "        return Vector(self.x + other.x, self.y + other.y)\n",
      "\n",
      "\n",
      "v1 = Vector(2, 3)\n",
      "v2 = Vector(1, 1)\n",
      "\n",
      "print(v1)  # Output: Vector(2, 3)  (Uses __str__)\n",
      "\n",
      "v3 = v1 + v2  # Uses __add__)\n",
      "print(v3)  # Output: Vector(3, 4)\n",
      "```\n",
      "\n",
      "**Key Improvements to Consider in Your Code (and Generally):**\n",
      "\n",
      "*   **Clarity and Readability:**  Write code that is easy to understand.  Use meaningful variable names, comments (where necessary, but prefer self-documenting code), and consistent formatting.\n",
      "*   **Correctness:**  Ensure your code produces the expected results and handles edge cases gracefully.\n",
      "*   **Efficiency:**  Optimize your code for performance, especially when dealing with large datasets or computationally intensive tasks.  Use appropriate data structures and algorithms.\n",
      "*   **Maintainability:**  Write code that is easy to modify and extend in the future.  Follow coding conventions and design patterns.\n",
      "*   **Testability:**  Write code that is easy to test.  Use unit tests to verify the correctness of your code.\n",
      "*   **Error Handling:**  Handle potential errors gracefully.  Use `try...except` blocks to catch exceptions and prevent your program from crashing.\n",
      "*   **Pythonic Style:**  Follow Python's coding conventions (PEP 8).  Use list comprehensions, generators, and other Pythonic features to write concise and expressive code.\n",
      "*   **Security:**  Be aware of potential security vulnerabilities in your code, such as SQL injection, cross-site scripting (XSS), and buffer overflows.  Use appropriate security measures to protect your code and data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_instruction = \"\"\"\n",
    "You are an expert in python programming, you will always provide idiomatic code, i.e. pythonic code. So when you see my code or my question be very \n",
    "critical, but answer in a concise way. Also be constructive to help me improve. \n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Explain OOP and dunder methods.\n",
    "\"\"\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.0-flash\",\n",
    "    contents = prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_instruction\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0f494e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=1149,\n",
       "  candidates_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=1149\n",
       "    ),\n",
       "  ],\n",
       "  prompt_token_count=66,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=66\n",
       "    ),\n",
       "  ],\n",
       "  total_token_count=1215\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata = response.usage_metadata\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48827a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.candidates_token_count = 1149\n",
      "metadata.prompt_token_count = 66\n",
      "metadata.total_token_count = 1215\n"
     ]
    }
   ],
   "source": [
    "print(f\"{metadata.candidates_token_count = }\") #output\n",
    "print(f\"{metadata.prompt_token_count = }\") # prompt + system instruction\n",
    "print(f\"{metadata.total_token_count = }\") # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "558f26c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 41)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt.split()), len(system_instruction.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b6f5a",
   "metadata": {},
   "source": [
    "## Temperature \n",
    "\n",
    "- controls randomness of output -> 'creative'\n",
    "- It's a hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de5bd9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gray rabbit twitched its nose, sensing the distant rumble of a lawnmower and immediately darted into the overgrown rose bushes, its fluffy tail disappearing in a flash of white. Safe within the thorny embrace, it nibbled on a fallen petal, the sweet scent masking the mechanical threat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story = \"write a 2 sentence story about a gray rabbit\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.0-flash\",\n",
    "    contents = story,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa239482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gray rabbit twitched its nose, sensing the distant rumble of a lawnmower and immediately darted into the overgrown rose bushes, its fluffy tail disappearing in a flash of white. Safe within the thorny embrace, it nibbled on a fallen petal, the sweet scent masking the mechanical threat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story = \"write a 2 sentence story about a gray rabbit\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.0-flash\",\n",
    "    contents = story,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f17e1a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dusty, a gray rabbit, hopped through the tall grass, his nose twitching, and followed the scent of carrots into Mr. McGregor's forbidden garden. He feasted on the orange delights, knowing he'd likely regret it later, but a rabbit's gotta eat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story = \"write a 2 sentence story about a gray rabbit\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model = \"gemini-2.0-flash\",\n",
    "    contents = story,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=2.0\n",
    "    ),\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d98f24",
   "metadata": {},
   "source": [
    "## Multimodal input\n",
    "\n",
    "input text and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1df3537c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A fluffy, gray rabbit is resting on a carpet while wearing a small, plush Swedish student graduation cap. The white and black cap has a blue and yellow ribbon draped over the rabbit's back.\n"
     ]
    }
   ],
   "source": [
    "text_input = \"Describe this image shortly\"\n",
    "image_input = {\"mime_type\": \"image/png\", \"data\": open(\"bella.png\", 'rb').read()}\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro\",\n",
    "    contents=dict(\n",
    "        parts=[dict(text = text_input), dict(inline_data = image_input)]\n",
    "    )\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac3a72f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-engineering-henrik-sjogren-de24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
